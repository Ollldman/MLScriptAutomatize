import pandas as pd
import logging
from typing import Any, Dict, Optional, Union
import os
from settings import settings

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


import kagglehub
from kagglehub import KaggleDatasetAdapter
from datasets import load_dataset as hf_load_dataset
from sklearn import datasets as sklearn_datasets
import requests
from io import StringIO, BytesIO


import os


# ========================
# LOADER FUNCTIONS
# ========================

def load_from_kaggle(dataset_id: str, filename: str, **kwargs) -> Optional[pd.DataFrame]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle —á–µ—Ä–µ–∑ kagglehub —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PANDAS –∞–¥–∞–ø—Ç–µ—Ä–∞.

    :param dataset_id: –ù–∞–ø—Ä–∏–º–µ—Ä, "username/dataset_name"
    :param filename: –ò–º—è —Ñ–∞–π–ª–∞ –≤–Ω—É—Ç—Ä–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "winemag-data-130k-v2.csv"). 
    :param kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã–µ –≤ pd.read_csv (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback)
    :return: pd.DataFrame –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    # –ü–æ–º–µ—â–∞–µ–º API kaggle –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–¥–∞–Ω—ã
    if not settings.KAGGLE_KEY and not settings.KAGGLE_KEY:
        logger.warning("–ù–µ –∑–∞–¥–∞–Ω—ã API credentials of Kaggle's public API")
        return None 
    else:
        os.environ["KAGGLE_USERNAME"] = settings.KAGGLE_USERNAME
        os.environ["KAGGLE_KEY"] = settings.KAGGLE_KEY
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle: {dataset_id}")
        data: pd.DataFrame = kagglehub.dataset_load(
            KaggleDatasetAdapter.PANDAS,
            dataset_id,
            filename,
            pandas_kwargs=kwargs
        )
        return data

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å Kaggle: {e}")
        return None
    



def load_from_huggingface(dataset_id: str, config_name: Optional[str] = None,
                          split: str = "train", **kwargs) -> Optional[pd.DataFrame]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å Hugging Face Datasets.

    :param dataset_id: –ù–∞–ø—Ä–∏–º–µ—Ä, "imdb", "glue", "rajpurkar/squad", –∏ —Ç.–¥.
    :param config_name: –ö–æ–Ω—Ñ–∏–≥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "mrpc" –¥–ª—è glue)
    :param split: "train", "test", "validation"
    :return: pd.DataFrame –∏–ª–∏ None
    """

    try:
        logger.info(f"ü§ó –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Hugging Face: {dataset_id}, split={split}")
        dataset = hf_load_dataset(dataset_id, config_name, split=split)
        df = dataset.to_pandas()
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        return df
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å Hugging Face: {e}")
        return None


def load_from_uci(url: str, **kwargs) -> Optional[pd.DataFrame]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å UCI Machine Learning Repository.

    :param url: –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ .data –∏–ª–∏ .csv —Ñ–∞–π–ª
    :return: pd.DataFrame –∏–ª–∏ None
    """
    try:
        logger.info(f"üåê –ó–∞–≥—Ä—É–∑–∫–∞ —Å UCI: {url}")
        response = requests.get(url)
        response.raise_for_status()

        # –ü–æ–ø—Ä–æ–±—É–µ–º –∫–∞–∫ CSV
        content = StringIO(response.text)
        df = pd.read_csv(content, **kwargs)
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        return df
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å UCI: {e}")
        return None


def load_from_sklearn(name: str, **kwargs) -> Optional[pd.DataFrame]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ sklearn.datasets.

    :param name: –ò–º—è —Ñ—É–Ω–∫—Ü–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, "load_iris", "load_boston", "fetch_california_housing"
    :return: pd.DataFrame –∏–ª–∏ None
    """
    if not SKLEARN_AVAILABLE:
        logger.error("sklearn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
        return None

    try:
        if not hasattr(sklearn_datasets, name):
            logger.error(f"–î–∞—Ç–∞—Å–µ—Ç '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ sklearn.datasets")
            return None

        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ sklearn: {name}")
        loader = getattr(sklearn_datasets, name)
        data = loader()

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
        if hasattr(data, 'frame') and data.frame is not None:
            df = data.frame
        else:
            df = pd.DataFrame(data.data, columns=data.feature_names)
            if hasattr(data, 'target'):
                target_name = 'target' if not hasattr(data, 'target_names') else 'target'
                df[target_name] = data.target

        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        return df
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ sklearn: {e}")
        return None


# ========================
# MAIN UNIVERSAL LOADER
# ========================

def load_dataset(source: str, **kwargs) -> Optional[pd.DataFrame]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:
      - 'kaggle': dataset_id, filename
      - 'huggingface': dataset_id, config_name, split
      - 'uci': url
      - 'sklearn': name

    –ü—Ä–∏–º–µ—Ä—ã:
      load_dataset('kaggle', dataset_id='zynicide/wine-reviews', filename='winemag-data_first150k.csv')
      load_dataset('huggingface', dataset_id='imdb', split='test')
      load_dataset('uci', url='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')
      load_dataset('sklearn', name='load_iris')
    """
    loaders = {
        'kaggle': load_from_kaggle,
        'huggingface': load_from_huggingface,
        'uci': load_from_uci,
        'sklearn': load_from_sklearn,
    }

    if source not in loaders:
        logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫: {source}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(loaders.keys())}")
        return None

    try:
        return loaders[source](**kwargs)
    except Exception as e:
        logger.error(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ {source}: {e}")
        return None